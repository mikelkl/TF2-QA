{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/dimitreOliveira/MachineLearning/master/Kaggle/TensorFlow%202.0%20Question%20Answering/banner.png\" width=\"1000\"></center>\n",
    "\n",
    "<br>\n",
    "<center><h1>Using Tensorflow 2.0 with Bert on Natural Questions - (translated to TF2.0)</h1></center>\n",
    "<br>\n",
    "\n",
    "### This is a translated version of the baseline [script](https://www.kaggle.com/philculliton/using-tensorflow-2-0-w-bert-on-nq) from the Tensorflow team\n",
    "\n",
    "#### I translated the script to the Tensorflow 2.0 version, this way we can take part in the TF2 prizes and may use the version to improve the work.\n",
    "\n",
    "**A few notes:**\n",
    "- If you want to keep using the flags you will have to use the \"absl\" lib (this is recommended by the TF team).\n",
    "- Since we won't use it with the kernels, I removed most of the TPU related stuff to reduce complexity.\n",
    "- I'm still translating the scripts.\n",
    "- If you have experience with Tensorflow 2 or have any correction/improvement, please let me know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll be using the Bert baseline for Tensorflow to create predictions for the Natural Questions test set. **Note that this uses a model that has already been pre-trained** - we're only doing inference here. A GPU is required, and this should take between 1-2 hours to run.\n",
    "\n",
    "The original script can be found [here](https://github.com/google-research/language/blob/master/language/question_answering/bert_joint/run_nq.py).\n",
    "The supporting modules were drawn from the [official Tensorflow model repository](https://github.com/tensorflow/models/tree/master/official). The bert-joint-baseline data is described [here](https://github.com/google-research/language/tree/master/language/question_answering/bert_joint).\n",
    "\n",
    "**Note:** This baseline uses code that was migrated from TF1.x. Be aware that it contains use of tf.compat.v1, which is not permitted to be eligible for [TF2.0 prizes in this competition](https://www.kaggle.com/c/tensorflow2-question-answering/overview/prizes). It is intended to be used as a starting point, but we're excited to see how much better you can do using TF2.0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T19:32:04.006412Z",
     "start_time": "2019-11-04T19:32:02.390397Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bertjointbaseline.zip\n",
      "../input/tensorflow2-question-answering/simplified-nq-test.jsonl\n",
      "../input/tensorflow2-question-answering/sample_submission.csv\n",
      "../input/tensorflow2-question-answering/simplified-nq-train.jsonl\n",
      "../input/tensorflow2-question-answering/.ipynb_checkpoints/sample_submission-checkpoint.csv\n",
      "../input/bertjointbaseline/bert_joint.ckpt.index\n",
      "../input/bertjointbaseline/bert_joint.ckpt.data-00000-of-00001\n",
      "../input/bertjointbaseline/bert_config.json\n",
      "../input/bertjointbaseline/vocab-nq.txt\n",
      "../input/bertjointbaseline/nq-train.tfrecords-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../bertjointbaseline\")\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import tf2_0_baseline_w_bert as tf2baseline # old script\n",
    "import tf2_0_baseline_w_bert_translated_to_tf2_0 as tf2baseline # my script\n",
    "import bert_modeling as modeling\n",
    "import bert_optimization as optimization\n",
    "import bert_tokenization as tokenization\n",
    "import json\n",
    "import absl\n",
    "import sys\n",
    "# from tf2_0_baseline_w_bert import *\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# In this case, we've got some extra BERT model files under `/kaggle/input/bertjointbaseline`\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow flags are variables that can be passed around within the TF system. Every flag below has some context provided regarding what the flag is and how it's used.\n",
    "\n",
    "#### Most of these can be changed as desired, with the exception of the Special Flags at the bottom, which _must_ stay as-is to work with the Kaggle back end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T19:32:04.039729Z",
     "start_time": "2019-11-04T19:32:04.009818Z"
    },
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/users/liukanglong/.conda/envs/QA/lib/python3.7/site-packages/ipykernel_launcher.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(absl.flags.FLAGS)\n",
    "\n",
    "flags = absl.flags\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"bert_config_file\", \"../input/bertjointbaseline/bert_config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", \"../input/bertjointbaseline/vocab-nq.txt\",\n",
    "                    \"The vocabulary file that the BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", \"../output/outdir\",\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "flags.DEFINE_string(\"train_precomputed_file\", None,\n",
    "                    \"Precomputed tf records for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_num_precomputed\", None,\n",
    "                     \"Number of precomputed tf records for training.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_prediction_file\", \"../output/predictions.json\",\n",
    "    \"Where to print predictions in NQ prediction format, to be passed to\"\n",
    "    \"natural_questions.nq_eval.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", \"../input/bertjointbaseline/bert_joint.ckpt\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"doc_stride\", 128,\n",
    "    \"When splitting up a long document into chunks, how much stride to \"\n",
    "    \"take between chunks.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_query_length\", 64,\n",
    "    \"The maximum number of tokens for the question. Questions longer than \"\n",
    "    \"this will be truncated to this length.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_predict\", True, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_batch_size\", 32, \"Total batch size for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 8,\n",
    "                     \"Total batch size for predictions.\")\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n",
    "\n",
    "flags.DEFINE_float(\"num_train_epochs\", 3.0,\n",
    "                   \"Total number of training epochs to perform.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"warmup_proportion\", 0.1,\n",
    "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    \"E.g., 0.1 = 10% of training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
    "                     \"How often to save the model checkpoint.\")\n",
    "\n",
    "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
    "                     \"How many steps to make in each estimator call.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_best_size\", 20,\n",
    "    \"The total number of n-best predictions to generate in the \"\n",
    "    \"nbest_predictions.json output file.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"verbosity\", 1, \"How verbose our error messages should be\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_answer_length\", 30,\n",
    "    \"The maximum length of an answer that can be generated. This is needed \"\n",
    "    \"because the start and end predictions are not conditioned on one another.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"include_unknowns\", -1.0,\n",
    "    \"If positive, probability of including answers of type `UNKNOWN`.\")\n",
    "\n",
    "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
    "flags.DEFINE_bool(\"use_one_hot_embeddings\", False, \"Whether to use use_one_hot_embeddings\")\n",
    "\n",
    "absl.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"verbose_logging\", False,\n",
    "    \"If true, all of the warnings related to data processing will be printed. \"\n",
    "    \"A number of warnings are expected for a normal NQ evaluation.\")\n",
    "\n",
    "flags.DEFINE_boolean(\n",
    "    \"skip_nested_contexts\", True,\n",
    "    \"Completely ignore context that are not top level nodes in the page.\")\n",
    "\n",
    "flags.DEFINE_integer(\"task_id\", 0,\n",
    "                     \"Train and dev shard to read from and write to.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_contexts\", 48,\n",
    "                     \"Maximum number of contexts to output for an example.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_position\", 50,\n",
    "    \"Maximum context position for which to generate special tokens.\")\n",
    "\n",
    "\n",
    "## Special flags - do not change\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"predict_file\", \"../input/tensorflow2-question-answering/simplified-nq-test.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "flags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\n",
    "flags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(sys.argv) # Parse the flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we:\n",
    "1. Set up Bert\n",
    "2. Read in the test set\n",
    "3. Run it past the pre-built Bert model to create embeddings\n",
    "4. Use those embeddings to make predictions\n",
    "5. Write those predictions to `predictions.json`\n",
    "\n",
    "Feel free to change the code below. Code for the `tf2baseline.*` functions is included in the `tf2_0_baseline_w_bert` utility script, and can be customized, whether by forking the utility script and updating it, or by creating your own non-`tf2baseline` versions in this kernel.\n",
    "\n",
    "Note: the `tf2_0_baseline_w_bert` utility script contains code for training your own embeddings. Here that code is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T21:18:48.602849Z",
     "start_time": "2019-11-04T19:41:05.739303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'outdir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98b604b310>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Reading: ../input/tensorflow2-question-answering/simplified-nq-test.jsonl\n",
      "FLAGS.predict_file ../input/tensorflow2-question-answering/simplified-nq-test.jsonl\n",
      "***** Running predictions *****\n",
      "  Num orig examples = 346\n",
      "  Num split examples = 9409\n",
      "  Batch size = 8\n",
      "  Num split into 3 = 8\n",
      "  Num split into 19 = 9\n",
      "  Num split into 50 = 5\n",
      "  Num split into 2 = 6\n",
      "  Num split into 34 = 6\n",
      "  Num split into 54 = 1\n",
      "  Num split into 40 = 7\n",
      "  Num split into 42 = 3\n",
      "  Num split into 22 = 7\n",
      "  Num split into 11 = 12\n",
      "  Num split into 29 = 8\n",
      "  Num split into 102 = 1\n",
      "  Num split into 60 = 3\n",
      "  Num split into 10 = 12\n",
      "  Num split into 21 = 6\n",
      "  Num split into 41 = 4\n",
      "  Num split into 6 = 7\n",
      "  Num split into 35 = 8\n",
      "  Num split into 23 = 4\n",
      "  Num split into 32 = 7\n",
      "  Num split into 17 = 10\n",
      "  Num split into 85 = 1\n",
      "  Num split into 30 = 6\n",
      "  Num split into 9 = 8\n",
      "  Num split into 1 = 7\n",
      "  Num split into 57 = 3\n",
      "  Num split into 5 = 9\n",
      "  Num split into 28 = 5\n",
      "  Num split into 31 = 7\n",
      "  Num split into 18 = 6\n",
      "  Num split into 47 = 5\n",
      "  Num split into 4 = 12\n",
      "  Num split into 67 = 1\n",
      "  Num split into 45 = 4\n",
      "  Num split into 27 = 7\n",
      "  Num split into 8 = 9\n",
      "  Num split into 63 = 1\n",
      "  Num split into 43 = 5\n",
      "  Num split into 13 = 9\n",
      "  Num split into 12 = 6\n",
      "  Num split into 16 = 6\n",
      "  Num split into 24 = 2\n",
      "  Num split into 14 = 4\n",
      "  Num split into 53 = 4\n",
      "  Num split into 20 = 5\n",
      "  Num split into 15 = 6\n",
      "  Num split into 7 = 6\n",
      "  Num split into 44 = 2\n",
      "  Num split into 112 = 1\n",
      "  Num split into 37 = 5\n",
      "  Num split into 46 = 3\n",
      "  Num split into 39 = 5\n",
      "  Num split into 87 = 1\n",
      "  Num split into 48 = 1\n",
      "  Num split into 33 = 2\n",
      "  Num split into 66 = 1\n",
      "  Num split into 49 = 3\n",
      "  Num split into 62 = 2\n",
      "  Num split into 125 = 1\n",
      "  Num split into 36 = 6\n",
      "  Num split into 26 = 8\n",
      "  Num split into 76 = 2\n",
      "  Num split into 121 = 1\n",
      "  Num split into 38 = 6\n",
      "  Num split into 55 = 1\n",
      "  Num split into 25 = 7\n",
      "  Num split into 56 = 3\n",
      "  Num split into 82 = 1\n",
      "  Num split into 58 = 1\n",
      "  Num split into 98 = 1\n",
      "  Num split into 52 = 1\n",
      "  Num split into 89 = 1\n",
      "  Num split into 73 = 1\n",
      "  Num split into 187 = 1\n",
      "outdir/eval.tf_record\n",
      "INFO:tensorflow:Could not find trained model in model_dir: outdir, running initialization to predict.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (None, 384)\n",
      "INFO:tensorflow:  name = input_mask, shape = (None, 384)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (None, 384)\n",
      "INFO:tensorflow:  name = unique_ids, shape = (None,)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert_model/word_embeddings/embeddings:0, shape = (30522, 1024)\n",
      "INFO:tensorflow:  name = bert_model/embedding_postprocessor/type_embeddings:0, shape = (2, 1024)\n",
      "INFO:tensorflow:  name = bert_model/embedding_postprocessor/position_embeddings:0, shape = (512, 1024)\n",
      "INFO:tensorflow:  name = bert_model/embedding_postprocessor/layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/embedding_postprocessor/layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_0/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_1/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/output/kernel:0, shape = (4096, 1024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_2/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_3/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_4/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_5/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_6/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_7/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention/query/bias:0, shape = (1024,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_8/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_9/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_10/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_11/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_12/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention/value/bias:0, shape = (1024,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_13/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_14/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_15/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_16/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_17/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/self_attention_layer_norm/beta:0, shape = (1024,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_18/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_19/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_20/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_21/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_22/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention/query/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention/query/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention/key/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention/key/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention/value/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention/value/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention_output/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention_output/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/self_attention_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/intermediate/kernel:0, shape = (1024, 4096)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/intermediate/bias:0, shape = (4096,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/output/kernel:0, shape = (4096, 1024)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/output/bias:0, shape = (1024,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/output_layer_norm/gamma:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/encoder/layer_23/output_layer_norm/beta:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = bert_model/pooler_transform/kernel:0, shape = (1024, 1024)\n",
      "INFO:tensorflow:  name = bert_model/pooler_transform/bias:0, shape = (1024,)\n",
      "INFO:tensorflow:  name = cls/nq/output_weights:0, shape = (2, 1024)\n",
      "INFO:tensorflow:  name = cls/nq/output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:  name = answer_type_output_weights:0, shape = (5, 1024)\n",
      "INFO:tensorflow:  name = answer_type_output_bias:0, shape = (5,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Processing example: 0\n",
      "Processing example: 1000\n",
      "Processing example: 2000\n",
      "Processing example: 3000\n",
      "Processing example: 4000\n",
      "Processing example: 5000\n",
      "Processing example: 6000\n",
      "Processing example: 7000\n",
      "Processing example: 8000\n",
      "Processing example: 9000\n",
      "Going to candidates file\n",
      "INFO:tensorflow:Reading examples from: ../input/tensorflow2-question-answering/simplified-nq-test.jsonl\n",
      "setting up eval features\n",
      "compute_pred_dict\n",
      "Examples processed: 100\n",
      "Examples processed: 200\n",
      "Examples processed: 300\n",
      "writing json\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "../output/predictions.json; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c7c609b666f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_prediction_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/QA/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/QA/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m\"\"\"Writes file_content to the file. Appends to the end of the file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     pywrap_tensorflow.AppendToFile(\n\u001b[1;32m    108\u001b[0m         compat.as_bytes(file_content), self._writable_file)\n",
      "\u001b[0;32m~/.conda/envs/QA/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_prewrite_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m                                            \"File isn't open for writing\")\n\u001b[1;32m     91\u001b[0m       self._writable_file = pywrap_tensorflow.CreateWritableFile(\n\u001b[0;32m---> 92\u001b[0;31m           compat.as_bytes(self.__name), compat.as_bytes(self.__mode))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ../output/predictions.json; No such file or directory"
     ]
    }
   ],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "\n",
    "tf2baseline.validate_flags_or_throw(bert_config)\n",
    "tf.io.gfile.makedirs(FLAGS.output_dir)\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps)\n",
    "\n",
    "num_train_steps = None\n",
    "num_warmup_steps = None\n",
    "\n",
    "model_fn = tf2baseline.model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    init_checkpoint=FLAGS.init_checkpoint,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    use_one_hot_embeddings=FLAGS.use_one_hot_embeddings)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    params={'batch_size': FLAGS.train_batch_size})\n",
    "\n",
    "if FLAGS.do_predict:\n",
    "    if not FLAGS.output_prediction_file:\n",
    "        raise ValueError(\n",
    "            \"--output_prediction_file must be defined in predict mode.\")\n",
    "\n",
    "    eval_examples = tf2baseline.read_nq_examples(\n",
    "        input_file=FLAGS.predict_file, is_training=False)\n",
    "\n",
    "    print(\"FLAGS.predict_file\", FLAGS.predict_file)\n",
    "\n",
    "    eval_writer = tf2baseline.FeatureWriter(\n",
    "        filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n",
    "        is_training=False)\n",
    "    eval_features = []\n",
    "\n",
    "\n",
    "    def append_feature(feature):\n",
    "        eval_features.append(feature)\n",
    "        eval_writer.process_feature(feature)\n",
    "\n",
    "\n",
    "    num_spans_to_ids = tf2baseline.convert_examples_to_features(\n",
    "        examples=eval_examples,\n",
    "        tokenizer=tokenizer,\n",
    "        is_training=False,\n",
    "        output_fn=append_feature)\n",
    "    eval_writer.close()\n",
    "    eval_filename = eval_writer.filename\n",
    "\n",
    "    print(\"***** Running predictions *****\")\n",
    "    print(f\"  Num orig examples = %d\" % len(eval_examples))\n",
    "    print(f\"  Num split examples = %d\" % len(eval_features))\n",
    "    print(f\"  Batch size = %d\" % FLAGS.predict_batch_size)\n",
    "    for spans, ids in num_spans_to_ids.items():\n",
    "        print(f\"  Num split into %d = %d\" % (spans, len(ids)))\n",
    "\n",
    "    predict_input_fn = tf2baseline.input_fn_builder(\n",
    "        input_file=eval_filename,\n",
    "        seq_length=FLAGS.max_seq_length,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    print(eval_filename)\n",
    "\n",
    "    # If running eval on the TPU, you will need to specify the number of steps.\n",
    "    all_results = []\n",
    "\n",
    "    for result in estimator.predict(\n",
    "            predict_input_fn, yield_single_examples=True):\n",
    "        if len(all_results) % 1000 == 0:\n",
    "            print(\"Processing example: %d\" % (len(all_results)))\n",
    "\n",
    "        unique_id = int(result[\"unique_ids\"])\n",
    "        start_logits = [float(x) for x in result[\"start_logits\"].flat]\n",
    "        end_logits = [float(x) for x in result[\"end_logits\"].flat]\n",
    "        answer_type_logits = [float(x) for x in result[\"answer_type_logits\"].flat]\n",
    "\n",
    "        all_results.append(\n",
    "            tf2baseline.RawResult(\n",
    "                unique_id=unique_id,\n",
    "                start_logits=start_logits,\n",
    "                end_logits=end_logits,\n",
    "                answer_type_logits=answer_type_logits))\n",
    "\n",
    "    print(\"Going to candidates file\")\n",
    "\n",
    "    candidates_dict = tf2baseline.read_candidates(FLAGS.predict_file)\n",
    "\n",
    "    print(\"setting up eval features\")\n",
    "\n",
    "    raw_dataset = tf.data.TFRecordDataset(eval_filename)\n",
    "    eval_features = []\n",
    "    for raw_record in raw_dataset:\n",
    "        eval_features.append(tf.train.Example.FromString(raw_record.numpy()))\n",
    "\n",
    "    print(\"compute_pred_dict\")\n",
    "\n",
    "    nq_pred_dict = tf2baseline.compute_pred_dict(candidates_dict, eval_features,\n",
    "                                                 [r._asdict() for r in all_results])\n",
    "    predictions_json = {\"predictions\": list(nq_pred_dict.values())}\n",
    "\n",
    "    print(\"writing json\")\n",
    "\n",
    "    with tf.io.gfile.GFile(FLAGS.output_prediction_file, \"w\") as f:\n",
    "        json.dump(predictions_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we turn `predictions.json` into a `submission.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:23.796699Z",
     "start_time": "2019-11-05T09:18:23.781729Z"
    }
   },
   "outputs": [],
   "source": [
    "test_answers_df = pd.read_json(\"../output/predictions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bert model produces a `confidence` score, which the Kaggle metric does not use. You, however, can use that score to determine which answers get submitted. See the limits commented out in `create_short_answer` and `create_long_answer` below for an example.\n",
    "\n",
    "Values for `confidence` will range between `1.0` and `2.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:25.071995Z",
     "start_time": "2019-11-05T09:18:25.061878Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_short_answer(entry):\n",
    "    # if entry[\"short_answers_score\"] < 1.5:\n",
    "    #     return \"\"\n",
    "    \n",
    "    answer = []    \n",
    "    for short_answer in entry[\"short_answers\"]:\n",
    "        if short_answer[\"start_token\"] > -1:\n",
    "            answer.append(str(short_answer[\"start_token\"]) + \":\" + str(short_answer[\"end_token\"]))\n",
    "    if entry[\"yes_no_answer\"] != \"NONE\":\n",
    "        answer.append(entry[\"yes_no_answer\"])\n",
    "    return \" \".join(answer)\n",
    "\n",
    "def create_long_answer(entry):\n",
    "   # if entry[\"long_answer_score\"] < 1.5:\n",
    "   # return \"\"\n",
    "\n",
    "    answer = []\n",
    "    if entry[\"long_answer\"][\"start_token\"] > -1:\n",
    "        answer.append(str(entry[\"long_answer\"][\"start_token\"]) + \":\" + str(entry[\"long_answer\"][\"end_token\"]))\n",
    "    return \" \".join(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:27.332668Z",
     "start_time": "2019-11-05T09:18:27.327703Z"
    }
   },
   "outputs": [],
   "source": [
    "test_answers_df[\"long_answer_score\"] = test_answers_df[\"predictions\"].apply(lambda q: q[\"long_answer_score\"])\n",
    "test_answers_df[\"short_answer_score\"] = test_answers_df[\"predictions\"].apply(lambda q: q[\"short_answers_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:27.996365Z",
     "start_time": "2019-11-05T09:18:27.988861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    346.000000\n",
       "mean       1.531710\n",
       "std        0.172828\n",
       "min        0.000000\n",
       "25%        1.434122\n",
       "50%        1.527620\n",
       "75%        1.624831\n",
       "max        2.159126\n",
       "Name: long_answer_score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_answers_df[\"long_answer_score\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of what each sample's answers look like in `prediction.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:30.533710Z",
     "start_time": "2019-11-05T09:18:30.526696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_id': '-1220107454853145579',\n",
       " 'long_answer': {'start_token': 18,\n",
       "  'end_token': 136,\n",
       "  'start_byte': -1,\n",
       "  'end_byte': -1},\n",
       " 'long_answer_score': 1.4369705617427821,\n",
       " 'short_answers': [{'start_token': 107,\n",
       "   'end_token': 129,\n",
       "   'start_byte': -1,\n",
       "   'end_byte': -1}],\n",
       " 'short_answers_score': 1.4369705617427821,\n",
       " 'yes_no_answer': 'NONE'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_answers_df.predictions.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-format the JSON answers to match the requirements for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:32.141368Z",
     "start_time": "2019-11-05T09:18:32.129179Z"
    }
   },
   "outputs": [],
   "source": [
    "test_answers_df[\"long_answer\"] = test_answers_df[\"predictions\"].apply(create_long_answer)\n",
    "test_answers_df[\"short_answer\"] = test_answers_df[\"predictions\"].apply(create_short_answer)\n",
    "test_answers_df[\"example_id\"] = test_answers_df[\"predictions\"].apply(lambda q: str(q[\"example_id\"]))\n",
    "\n",
    "long_answers = dict(zip(test_answers_df[\"example_id\"], test_answers_df[\"long_answer\"]))\n",
    "short_answers = dict(zip(test_answers_df[\"example_id\"], test_answers_df[\"short_answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add them to our sample submission. Recall that each sample has both a `_long` and `_short` entry in the sample submission, one for each type of answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:33.782392Z",
     "start_time": "2019-11-05T09:18:33.750415Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/tensorflow2-question-answering/sample_submission.csv\")\n",
    "\n",
    "long_prediction_strings = sample_submission[sample_submission[\"example_id\"].str.contains(\"_long\")].apply(lambda q: long_answers[q[\"example_id\"].replace(\"_long\", \"\")], axis=1)\n",
    "short_prediction_strings = sample_submission[sample_submission[\"example_id\"].str.contains(\"_short\")].apply(lambda q: short_answers[q[\"example_id\"].replace(\"_short\", \"\")], axis=1)\n",
    "\n",
    "sample_submission.loc[sample_submission[\"example_id\"].str.contains(\"_long\"), \"PredictionString\"] = long_prediction_strings\n",
    "sample_submission.loc[sample_submission[\"example_id\"].str.contains(\"_short\"), \"PredictionString\"] = short_prediction_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we write out our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T09:18:35.022131Z",
     "start_time": "2019-11-05T09:18:35.003525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1011141123527297803_long</td>\n",
       "      <td>277:339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1011141123527297803_short</td>\n",
       "      <td>331:334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1028916936938579349_long</td>\n",
       "      <td>42:321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1028916936938579349_short</td>\n",
       "      <td>160:205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1055197305756217938_long</td>\n",
       "      <td>16:221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   example_id PredictionString\n",
       "0   -1011141123527297803_long          277:339\n",
       "1  -1011141123527297803_short          331:334\n",
       "2   -1028916936938579349_long           42:321\n",
       "3  -1028916936938579349_short          160:205\n",
       "4   -1055197305756217938_long           16:221"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.to_csv(\"../output/submission.csv\", index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-QA]",
   "language": "python",
   "name": "conda-env-.conda-QA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
